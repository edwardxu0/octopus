name = 'test'                                   # name of test case

[train]
	artifact = 'MNIST'                          # which dataset?
	net_name = 'NetS'
	net_layers = [32,32]

	epochs = 5
	batch_size = 32
	test_batch_size = 32
	lr = 1e-4							       
	gamma = 0.95 							    # Learning rate decay
	save_model = true
	save_intermediate = true                    # save intermediate models
	save_log = true                             # save training log
	log_interval = 100			         		# stable ReLU estimation/print interval
	gpu = false                                 # use gpu?
	amp = true					         		# enabled only when gpu == true. CUDA 
	adv_train = 'nature' 			 	        # normal training

	# SDD: sampled dataset distribution
	# SAD: sampled adversarial distribution
	# NIP: naive interval propagation
	# SIP: symbolic interval propagation
	# ALR: automated liRPA estimator(CROWN)
	# ALRo: automated liRPA estimator(CROWN with alpha)
	[train.stable_estimators]
		[train.stable_estimators.SDD]
		
		[train.stable_estimators.SAD]
			epsilon = 0.08

		[train.stable_estimators.NIP]
			epsilon = 0.08
			
		[train.stable_estimators.SIP]
			epsilon = 0.08
		
		[train.stable_estimators.ALR]
			method = 'CROWN'
			epsilon = 0.08

[stabilizers]

	# enables bias shaping stabilizer
	[stabilizers.bias_shaping]
		mode = 'standard'
		
		# interval scheduling
		intensity = 2e-2                        # intensity
		pace = 100                              # occurance
		#decay = 0.99                           # intensity decay
		
		# epochs to start and end bias shaping
		start = 1 			                    # inclusive
		end = 5 			                    # inclusive

		# use this estimator with bias shaping
		[stabilizers.bias_shaping.stable_estimators]
			[stabilizers.bias_shaping.stable_estimators.SDD]
				epsilon = 0.08

	# enables RS Loss stabilizer
	[stabilizers.rs_loss]
		mode = 'standard'
		weight = 1e-4                            # weight for unstable ReLU term
		start = 1
		end = 5
		
		# use this estimator with rs loss
		[stabilizers.rs_loss.stable_estimators]
			[stabilizers.rs_loss.stable_estimators.SIP]
				epsilon = 0.08

	# enables Stable Pruning stabilizer
	[stabilizers.stable_prune]
		mode = 'standard'
		#re_arch = 'last'
		#save_re_arch = true
		sparsity = 2e-2
		pace = 100

		start = 1
		end = 5
		[stabilizers.stable_prune.stable_estimators]
			[stabilizers.stable_prune.stable_estimators.ALR]
				method = 'CROWN'
				epsilon = 0.08




[verify]
	time = 600
	memory = '8G'
	property = 1
	epsilon = 0.02
	debug = true
	save_log = false
	
	verifier = 'nnenum'
	#verifier = 'abcrown'
	#verifier = 'mnbab'
	
	
	# model selection strategy for verification
	# last(default): last epoch model
	#
	# For all below: must save intermediate models(save_intermediate = true)
	# best test accuracy: model with the best test accuracy
	# best relu accuracy: model with the most amount of stable relus
	# top [x] test accuaracy: model with the most amount of stable relus with [x]% accuarcy difference of the model with the best tests accuracy
	# top [x] relu accuaracy: model with the best test accuracy with [x]% stable relu difference of the model with the most amount of stable relus
	# target_model = 'last'
	target_model = 'best test accuracy of last 5 epochs'