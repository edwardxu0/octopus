name = 'test'

[train]
	artifact = 'CIFAR10'
	net_name = 'LeNet2'

	epochs = 20
	batch_size = 128
	test_batch_size = 128
	lr = 1e-4							# learning rate
	gamma = 0.95 							# Learning rate decay
	save_model = true
	save_intermediate = true
	save_log = true
	log_interval = 100					# Stable ReLU estimation/print interval
	amp = true							# enabled only when gpu == true

	adv_train = 'nature' 				# ['nature', 'pgd', 'vae', 'gan', ...]


	# SDD: sampled dataset distribution
	# SAD: sampled adversarial distribution
	# NIP: interval propagation
	[train.stable_estimators]
		[train.stable_estimators.SDD]
		
		[train.stable_estimators.SAD]
			epsilon = 0.04
			samples = 100

	#	[train.stable_estimators.NIP]
	#		epsilon = 0.04
			
	#	[train.stable_estimators.SIP]
	#		epsilon = 0.04

[stabilizers]
	[stabilizers.bias_shaping]
		mode = 'standard'
		
		# random scheduling
		# intensity =  5e-2
        # occurrence = 5e-3

		# interval scheduling
		intensity = 2e-2
		# pace = 1
		pace = 50
		# decay = 0.99
		
		start = 1 			# inclusive
		end = 20 			# inclusive
		[stabilizers.bias_shaping.stable_estimators]
			[stabilizers.bias_shaping.stable_estimators.SDD]
				epsilon = 0.04
				samples = 100

	#[stabilizers.rs_loss]
	#	mode = 'standard'
	#	weight = 1e-4
	#	epsilon = 0.1
	#	start = 1
	#	end = 20
	#	[stabilizers.rs_loss.stable_estimators]
	#		[stabilizers.rs_loss.stable_estimators.SIP]
	#			epsilon = 0.04
	#			

	#[stabilizers.stable_prune]
	#	mode = 'structure'
	#	#re_arch = 'last'
	#	save_re_arch = true
	#	sparsity = 0.05

	#	start = 1
	#	end = 10
	#	[stabilizers.stable_prune.stable_estimators]
	#		[stabilizers.stable_prune.stable_estimators.SIP]
	#			epsilon = 0.04
	#			samples = 10




[verify]
	time = 600
	memory = '8G'
	property = 0
	epsilon = 0.001
	debug = true
	save_log = true
	verifier = 'DNNVWB:neurify'
	
	# model selection strategy for verification
	# last(default): last epoch model
	#
	# For all below: must save intermediate models(save_intermediate = true)
	# best test accuracy: model with the best test accuracy
	# best relu accuracy: model with the most amount of stable relus
	# top [x] test accuaracy: model with the most amount of stable relus with [x]% accuarcy difference of the model with the best tests accuracy
	# top [x] relu accuaracy: model with the best test accuracy with [x]% stable relu difference of the model with the most amount of stable relus
	# target_model = 'last'
	target_model = 'best test accuracy of last 5 epochs'