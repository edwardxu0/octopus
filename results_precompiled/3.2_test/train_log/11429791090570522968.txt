Network:
ReLUNet(
  (Flatten1): Flatten(start_dim=1, end_dim=-1)
  (FC1): Linear(in_features=784, out_features=32, bias=True)
  (ReLU1): ReLU()
  (FC2): Linear(in_features=32, out_features=32, bias=True)
  (ReLU2): ReLU()
  (Out): Linear(in_features=32, out_features=10, bias=True)
)
# ReLUs: 64
Train stability estimators: ['SDD', 'SAD', 'NIP', 'SIP', 'ALR']
Train stabilizers: ['Bias Shaping(SDD)', 'RS Loss(SIP)', 'Prune(ALR)']
[Train] epoch:   1 batch:     0  0.00% Loss:   2.317464
[Train] Stable ReLUs: SDD: 17.19% SAD: 17.19% NIP: 0.00% SIP: 0.00% ALR: 0.00% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   1 batch:   100  5.33% Loss:   2.185595
[Train] Stable ReLUs: SDD: 21.88% SAD: 18.75% NIP: 7.23% SIP: 7.91% ALR: 8.40% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   1 batch:   200 10.67% Loss:   2.019176
[Train] Stable ReLUs: SDD: 20.31% SAD: 25.00% NIP: 21.68% SIP: 32.67% ALR: 34.42% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   1 batch:   300 16.00% Loss:   1.767639
[Train] Stable ReLUs: SDD: 29.69% SAD: 35.94% NIP: 34.96% SIP: 59.86% ALR: 60.60% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   1 batch:   400 21.33% Loss:   1.540809
[Train] Stable ReLUs: SDD: 29.69% SAD: 35.94% NIP: 36.91% SIP: 62.11% ALR: 62.60% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   1 batch:   500 26.67% Loss:   1.282817
[Train] Stable ReLUs: SDD: 31.25% SAD: 34.38% NIP: 42.24% SIP: 66.50% ALR: 67.19% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   1 batch:   600 32.00% Loss:   1.136023
[Train] Stable ReLUs: SDD: 26.56% SAD: 32.81% NIP: 47.22% SIP: 71.97% ALR: 72.61% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   1 batch:   700 37.33% Loss:   1.008559
[Train] Stable ReLUs: SDD: 32.81% SAD: 46.88% NIP: 46.83% SIP: 72.41% ALR: 72.51% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   1 batch:   800 42.67% Loss:   0.664491
[Train] Stable ReLUs: SDD: 32.81% SAD: 40.62% NIP: 51.90% SIP: 73.58% ALR: 74.17% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   1 batch:   900 48.00% Loss:   0.585737
[Train] Stable ReLUs: SDD: 35.94% SAD: 43.75% NIP: 50.00% SIP: 73.19% ALR: 73.58% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   1 batch:  1000 53.33% Loss:   0.710903
[Train] Stable ReLUs: SDD: 34.38% SAD: 43.75% NIP: 53.91% SIP: 74.80% ALR: 75.20% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   1 batch:  1100 58.67% Loss:   0.907127
[Train] Stable ReLUs: SDD: 39.06% SAD: 48.44% NIP: 56.79% SIP: 80.71% ALR: 80.81% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   1 batch:  1200 64.00% Loss:   0.666718
[Train] Stable ReLUs: SDD: 43.75% SAD: 53.12% NIP: 50.68% SIP: 74.76% ALR: 74.90% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   1 batch:  1300 69.33% Loss:   0.576496
[Train] Stable ReLUs: SDD: 32.81% SAD: 39.06% NIP: 52.73% SIP: 76.95% ALR: 77.20% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   1 batch:  1400 74.67% Loss:   0.423454
[Train] Stable ReLUs: SDD: 23.44% SAD: 34.38% NIP: 54.15% SIP: 75.63% ALR: 75.78% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   1 batch:  1500 80.00% Loss:   0.514909
[Train] Stable ReLUs: SDD: 31.25% SAD: 45.31% NIP: 53.42% SIP: 75.39% ALR: 75.54% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   1 batch:  1600 85.33% Loss:   0.286631
[Train] Stable ReLUs: SDD: 35.94% SAD: 42.19% NIP: 57.62% SIP: 77.20% ALR: 77.49% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   1 batch:  1700 90.67% Loss:   0.698632
[Train] Stable ReLUs: SDD: 25.00% SAD: 32.81% NIP: 53.32% SIP: 71.14% ALR: 71.44% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   1 batch:  1800 96.00% Loss:   0.613928
[Train] Stable ReLUs: SDD: 31.25% SAD: 43.75% NIP: 52.59% SIP: 75.39% ALR: 75.73% 
[Test] epoch:   1 loss:   0.456226, accuracy: 88.30%
[Test] Stable ReLUs: SDD: 42.19% SAD: 56.25% NIP: 52.44% SIP: 78.03% ALR: 78.32% 

[Train] epoch:   2 batch:     0  0.00% Loss:   0.521408
[Train] Stable ReLUs: SDD: 34.38% SAD: 43.75% NIP: 52.29% SIP: 73.14% ALR: 73.49% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   2 batch:   100  5.33% Loss:   0.600841
[Train] Stable ReLUs: SDD: 31.25% SAD: 34.38% NIP: 56.79% SIP: 78.56% ALR: 78.81% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   2 batch:   200 10.67% Loss:   0.357927
[Train] Stable ReLUs: SDD: 35.94% SAD: 42.19% NIP: 55.62% SIP: 75.93% ALR: 76.12% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   2 batch:   300 16.00% Loss:   0.468785
[Train] Stable ReLUs: SDD: 25.00% SAD: 31.25% NIP: 52.73% SIP: 76.22% ALR: 76.32% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   2 batch:   400 21.33% Loss:   0.456063
[Train] Stable ReLUs: SDD: 26.56% SAD: 39.06% NIP: 54.69% SIP: 76.71% ALR: 77.00% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   2 batch:   500 26.67% Loss:   0.361107
[Train] Stable ReLUs: SDD: 34.38% SAD: 42.19% NIP: 57.96% SIP: 78.81% ALR: 79.10% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   2 batch:   600 32.00% Loss:   0.401849
[Train] Stable ReLUs: SDD: 42.19% SAD: 56.25% NIP: 55.96% SIP: 77.64% ALR: 78.12% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   2 batch:   700 37.33% Loss:   0.401014
[Train] Stable ReLUs: SDD: 32.81% SAD: 51.56% NIP: 55.22% SIP: 76.37% ALR: 76.56% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   2 batch:   800 42.67% Loss:   0.449359
[Train] Stable ReLUs: SDD: 50.00% SAD: 54.69% NIP: 56.64% SIP: 77.69% ALR: 77.78% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   2 batch:   900 48.00% Loss:   0.489461
[Train] Stable ReLUs: SDD: 39.06% SAD: 45.31% NIP: 54.54% SIP: 76.76% ALR: 77.05% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   2 batch:  1000 53.33% Loss:   0.405872
[Train] Stable ReLUs: SDD: 46.88% SAD: 59.38% NIP: 56.84% SIP: 77.83% ALR: 78.17% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   2 batch:  1100 58.67% Loss:   0.399428
[Train] Stable ReLUs: SDD: 35.94% SAD: 46.88% NIP: 51.61% SIP: 74.61% ALR: 74.80% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   2 batch:  1200 64.00% Loss:   0.358401
[Train] Stable ReLUs: SDD: 37.50% SAD: 42.19% NIP: 54.44% SIP: 75.73% ALR: 76.17% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   2 batch:  1300 69.33% Loss:   0.420850
[Train] Stable ReLUs: SDD: 45.31% SAD: 51.56% NIP: 52.10% SIP: 76.12% ALR: 76.32% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   2 batch:  1400 74.67% Loss:   0.474621
[Train] Stable ReLUs: SDD: 39.06% SAD: 42.19% NIP: 50.49% SIP: 70.90% ALR: 71.34% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   2 batch:  1500 80.00% Loss:   0.665544
[Train] Stable ReLUs: SDD: 34.38% SAD: 46.88% NIP: 53.71% SIP: 76.56% ALR: 76.71% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   2 batch:  1600 85.33% Loss:   0.223246
[Train] Stable ReLUs: SDD: 29.69% SAD: 48.44% NIP: 54.93% SIP: 77.34% ALR: 77.44% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   2 batch:  1700 90.67% Loss:   0.246880
[Train] Stable ReLUs: SDD: 45.31% SAD: 54.69% NIP: 53.86% SIP: 76.81% ALR: 76.95% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   2 batch:  1800 96.00% Loss:   0.445285
[Train] Stable ReLUs: SDD: 42.19% SAD: 48.44% NIP: 52.88% SIP: 76.32% ALR: 76.56% 
[Test] epoch:   2 loss:   0.350101, accuracy: 90.30%
[Test] Stable ReLUs: SDD: 60.94% SAD: 65.62% NIP: 60.74% SIP: 82.91% ALR: 83.30% 

[Train] epoch:   3 batch:     0  0.00% Loss:   0.328960
[Train] Stable ReLUs: SDD: 35.94% SAD: 48.44% NIP: 52.59% SIP: 75.49% ALR: 75.78% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   3 batch:   100  5.33% Loss:   0.275476
[Train] Stable ReLUs: SDD: 31.25% SAD: 39.06% NIP: 51.17% SIP: 73.83% ALR: 74.07% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   3 batch:   200 10.67% Loss:   0.336446
[Train] Stable ReLUs: SDD: 39.06% SAD: 43.75% NIP: 53.81% SIP: 76.07% ALR: 76.32% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   3 batch:   300 16.00% Loss:   0.524626
[Train] Stable ReLUs: SDD: 39.06% SAD: 48.44% NIP: 53.81% SIP: 77.64% ALR: 77.73% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   3 batch:   400 21.33% Loss:   0.305080
[Train] Stable ReLUs: SDD: 43.75% SAD: 51.56% NIP: 58.84% SIP: 80.13% ALR: 80.37% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   3 batch:   500 26.67% Loss:   0.416257
[Train] Stable ReLUs: SDD: 37.50% SAD: 40.62% NIP: 53.27% SIP: 73.78% ALR: 74.02% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   3 batch:   600 32.00% Loss:   0.337580
[Train] Stable ReLUs: SDD: 39.06% SAD: 50.00% NIP: 55.47% SIP: 75.20% ALR: 75.63% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   3 batch:   700 37.33% Loss:   0.399222
[Train] Stable ReLUs: SDD: 34.38% SAD: 43.75% NIP: 51.86% SIP: 74.76% ALR: 74.80% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   3 batch:   800 42.67% Loss:   0.346116
[Train] Stable ReLUs: SDD: 23.44% SAD: 29.69% NIP: 53.86% SIP: 75.88% ALR: 76.37% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   3 batch:   900 48.00% Loss:   0.233125
[Train] Stable ReLUs: SDD: 34.38% SAD: 40.62% NIP: 56.35% SIP: 78.17% ALR: 78.37% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   3 batch:  1000 53.33% Loss:   0.396461
[Train] Stable ReLUs: SDD: 39.06% SAD: 43.75% NIP: 54.59% SIP: 76.03% ALR: 76.27% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   3 batch:  1100 58.67% Loss:   0.452158
[Train] Stable ReLUs: SDD: 40.62% SAD: 53.12% NIP: 55.08% SIP: 76.81% ALR: 77.15% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   3 batch:  1200 64.00% Loss:   0.443547
[Train] Stable ReLUs: SDD: 37.50% SAD: 45.31% NIP: 54.64% SIP: 76.86% ALR: 77.05% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   3 batch:  1300 69.33% Loss:   0.324463
[Train] Stable ReLUs: SDD: 34.38% SAD: 43.75% NIP: 54.83% SIP: 76.76% ALR: 76.86% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   3 batch:  1400 74.67% Loss:   0.367557
[Train] Stable ReLUs: SDD: 42.19% SAD: 51.56% NIP: 51.17% SIP: 74.56% ALR: 74.85% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   3 batch:  1500 80.00% Loss:   0.219020
[Train] Stable ReLUs: SDD: 37.50% SAD: 40.62% NIP: 54.20% SIP: 76.71% ALR: 76.90% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   3 batch:  1600 85.33% Loss:   0.338816
[Train] Stable ReLUs: SDD: 35.94% SAD: 50.00% NIP: 50.29% SIP: 73.78% ALR: 73.97% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   3 batch:  1700 90.67% Loss:   0.313859
[Train] Stable ReLUs: SDD: 43.75% SAD: 50.00% NIP: 52.73% SIP: 75.44% ALR: 75.68% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   3 batch:  1800 96.00% Loss:   0.483410
[Train] Stable ReLUs: SDD: 39.06% SAD: 46.88% NIP: 53.08% SIP: 76.17% ALR: 76.32% 
[Test] epoch:   3 loss:   0.311918, accuracy: 91.18%
[Test] Stable ReLUs: SDD: 54.69% SAD: 60.94% NIP: 51.46% SIP: 75.39% ALR: 75.59% 

[Train] epoch:   4 batch:     0  0.00% Loss:   0.312845
[Train] Stable ReLUs: SDD: 46.88% SAD: 50.00% NIP: 54.05% SIP: 75.15% ALR: 75.29% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   4 batch:   100  5.33% Loss:   0.169621
[Train] Stable ReLUs: SDD: 42.19% SAD: 46.88% NIP: 55.52% SIP: 78.81% ALR: 79.10% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   4 batch:   200 10.67% Loss:   0.293903
[Train] Stable ReLUs: SDD: 46.88% SAD: 56.25% NIP: 53.27% SIP: 76.71% ALR: 76.90% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   4 batch:   300 16.00% Loss:   0.379549
[Train] Stable ReLUs: SDD: 45.31% SAD: 50.00% NIP: 51.46% SIP: 73.39% ALR: 73.58% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   4 batch:   400 21.33% Loss:   0.373031
[Train] Stable ReLUs: SDD: 40.62% SAD: 51.56% NIP: 53.56% SIP: 75.83% ALR: 76.12% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   4 batch:   500 26.67% Loss:   0.091365
[Train] Stable ReLUs: SDD: 43.75% SAD: 53.12% NIP: 51.51% SIP: 72.90% ALR: 73.49% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   4 batch:   600 32.00% Loss:   0.276106
[Train] Stable ReLUs: SDD: 28.12% SAD: 39.06% NIP: 50.83% SIP: 73.68% ALR: 73.68% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   4 batch:   700 37.33% Loss:   0.333492
[Train] Stable ReLUs: SDD: 37.50% SAD: 45.31% NIP: 52.54% SIP: 74.12% ALR: 74.51% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   4 batch:   800 42.67% Loss:   0.497829
[Train] Stable ReLUs: SDD: 45.31% SAD: 45.31% NIP: 52.00% SIP: 74.46% ALR: 74.66% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   4 batch:   900 48.00% Loss:   0.279902
[Train] Stable ReLUs: SDD: 46.88% SAD: 56.25% NIP: 52.88% SIP: 75.73% ALR: 76.22% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   4 batch:  1000 53.33% Loss:   0.241201
[Train] Stable ReLUs: SDD: 35.94% SAD: 45.31% NIP: 56.01% SIP: 75.44% ALR: 75.63% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   4 batch:  1100 58.67% Loss:   0.143387
[Train] Stable ReLUs: SDD: 45.31% SAD: 51.56% NIP: 54.20% SIP: 76.17% ALR: 76.42% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   4 batch:  1200 64.00% Loss:   0.421923
[Train] Stable ReLUs: SDD: 42.19% SAD: 46.88% NIP: 52.73% SIP: 73.83% ALR: 74.07% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   4 batch:  1300 69.33% Loss:   0.406929
[Train] Stable ReLUs: SDD: 40.62% SAD: 46.88% NIP: 53.71% SIP: 74.51% ALR: 74.76% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   4 batch:  1400 74.67% Loss:   0.229626
[Train] Stable ReLUs: SDD: 39.06% SAD: 46.88% NIP: 50.29% SIP: 73.34% ALR: 73.88% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   4 batch:  1500 80.00% Loss:   0.130064
[Train] Stable ReLUs: SDD: 45.31% SAD: 53.12% NIP: 52.29% SIP: 75.00% ALR: 75.39% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   4 batch:  1600 85.33% Loss:   0.514050
[Train] Stable ReLUs: SDD: 28.12% SAD: 37.50% NIP: 50.10% SIP: 72.71% ALR: 73.05% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   4 batch:  1700 90.67% Loss:   0.149087
[Train] Stable ReLUs: SDD: 37.50% SAD: 43.75% NIP: 50.39% SIP: 72.36% ALR: 72.46% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   4 batch:  1800 96.00% Loss:   0.272952
[Train] Stable ReLUs: SDD: 43.75% SAD: 48.44% NIP: 51.27% SIP: 72.02% ALR: 72.31% 
[Test] epoch:   4 loss:   0.292140, accuracy: 91.64%
[Test] Stable ReLUs: SDD: 46.88% SAD: 53.12% NIP: 49.41% SIP: 72.56% ALR: 72.75% 

[Train] epoch:   5 batch:     0  0.00% Loss:   0.090536
[Train] Stable ReLUs: SDD: 32.81% SAD: 40.62% NIP: 53.47% SIP: 74.02% ALR: 74.22% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   5 batch:   100  5.33% Loss:   0.343660
[Train] Stable ReLUs: SDD: 42.19% SAD: 48.44% NIP: 53.27% SIP: 74.76% ALR: 74.90% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   5 batch:   200 10.67% Loss:   0.077489
[Train] Stable ReLUs: SDD: 35.94% SAD: 45.31% NIP: 53.91% SIP: 73.88% ALR: 74.12% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   5 batch:   300 16.00% Loss:   0.174024
[Train] Stable ReLUs: SDD: 35.94% SAD: 45.31% NIP: 54.25% SIP: 74.80% ALR: 74.85% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   5 batch:   400 21.33% Loss:   0.501999
[Train] Stable ReLUs: SDD: 43.75% SAD: 50.00% NIP: 54.44% SIP: 77.39% ALR: 77.93% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   5 batch:   500 26.67% Loss:   0.179054
[Train] Stable ReLUs: SDD: 40.62% SAD: 46.88% NIP: 53.56% SIP: 76.42% ALR: 76.51% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   5 batch:   600 32.00% Loss:   0.480211
[Train] Stable ReLUs: SDD: 45.31% SAD: 50.00% NIP: 52.25% SIP: 75.83% ALR: 76.12% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   5 batch:   700 37.33% Loss:   0.090416
[Train] Stable ReLUs: SDD: 37.50% SAD: 53.12% NIP: 52.29% SIP: 72.80% ALR: 73.10% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   5 batch:   800 42.67% Loss:   0.122048
[Train] Stable ReLUs: SDD: 32.81% SAD: 39.06% NIP: 49.37% SIP: 73.19% ALR: 73.34% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   5 batch:   900 48.00% Loss:   0.193296
[Train] Stable ReLUs: SDD: 37.50% SAD: 46.88% NIP: 50.54% SIP: 72.46% ALR: 72.80% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   5 batch:  1000 53.33% Loss:   0.060124
[Train] Stable ReLUs: SDD: 34.38% SAD: 42.19% NIP: 53.71% SIP: 73.97% ALR: 74.22% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   5 batch:  1100 58.67% Loss:   0.196131
[Train] Stable ReLUs: SDD: 42.19% SAD: 48.44% NIP: 52.73% SIP: 74.37% ALR: 74.56% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   5 batch:  1200 64.00% Loss:   0.201277
[Train] Stable ReLUs: SDD: 42.19% SAD: 54.69% NIP: 50.83% SIP: 72.90% ALR: 73.14% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   5 batch:  1300 69.33% Loss:   0.375230
[Train] Stable ReLUs: SDD: 45.31% SAD: 50.00% NIP: 48.54% SIP: 72.07% ALR: 72.41% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   5 batch:  1400 74.67% Loss:   0.245867
[Train] Stable ReLUs: SDD: 45.31% SAD: 54.69% NIP: 48.63% SIP: 72.41% ALR: 72.71% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   5 batch:  1500 80.00% Loss:   0.381595
[Train] Stable ReLUs: SDD: 32.81% SAD: 42.19% NIP: 51.42% SIP: 73.63% ALR: 73.78% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   5 batch:  1600 85.33% Loss:   0.118010
[Train] Stable ReLUs: SDD: 34.38% SAD: 39.06% NIP: 47.22% SIP: 70.95% ALR: 71.48% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   5 batch:  1700 90.67% Loss:   0.080796
[Train] Stable ReLUs: SDD: 43.75% SAD: 46.88% NIP: 51.51% SIP: 74.02% ALR: 74.37% 
Prune starts here ...
Using iterative structure pruning ...
[Train] epoch:   5 batch:  1800 96.00% Loss:   0.191823
[Train] Stable ReLUs: SDD: 40.62% SAD: 45.31% NIP: 50.00% SIP: 71.68% ALR: 72.17% 
[Test] epoch:   5 loss:   0.273336, accuracy: 92.17%
[Test] Stable ReLUs: SDD: 46.88% SAD: 54.69% NIP: 48.93% SIP: 71.58% ALR: 71.68% 

Network name: 11429791090570522968.
Mission Complete.
Spent 1329.47 seconds.
